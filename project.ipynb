{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_avVIGTpvioI"
      },
      "source": [
        "# DX 704 Week 3 Project\n",
        "\n",
        "This week's project will give you practice with optimizing choices for bandit algorithms.\n",
        "You will be given access to the bandit problem via a blackbox object, and you will investigate the bandit rewards to pick a suitable algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftRkegOQowWA"
      },
      "source": [
        "The full project description, a template notebook and supporting code are available on GitHub: [Project 3 Materials](https://github.com/bu-cds-dx704/dx704-project-03).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tPHvNSEdR6h"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6VKDAEY8JMI"
      },
      "source": [
        "## Part 1: Pick a Bandit Algorithm\n",
        "\n",
        "Experiment with the multi-armed bandit interface using seed 0 to learn about the distribution of rewards and decide what kind of bandit algorithm will be appropriate.\n",
        "A histogram will likely be helpful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "BCggNE7NpiQN"
      },
      "outputs": [],
      "source": [
        "# DO NOT CHANGE\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BanditProblem(object):\n",
        "    def __init__(self, seed):\n",
        "        self.seed = seed\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "\n",
        "        self.num_arms = 3\n",
        "        self.ns = self.rng.integers(low=1, high=10, size=self.num_arms)\n",
        "        self.ps = self.rng.uniform(low=0.2, high=0.4, size=self.num_arms)\n",
        "\n",
        "    def get_num_arms(self):\n",
        "        return self.num_arms\n",
        "\n",
        "    def get_reward(self, arm):\n",
        "        if arm < 0 or arm >= self.num_arms:\n",
        "            raise ValueError(\"Invalid arm\")\n",
        "\n",
        "        x = self.rng.uniform()\n",
        "        x *= self.rng.binomial(self.ns[arm], self.ps[arm])\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "X99ZQUyhpgak"
      },
      "outputs": [],
      "source": [
        "bandit0 = BanditProblem(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "frDtVjt4qATJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bandit0.get_num_arms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "sdM9Ec3HqC6h"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.8255111545554434"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bandit0.get_reward(arm=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "iuQ0jCr_plcZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arm 0:\n",
            "  Mean: 0.8150\n",
            "  Std:  0.7839\n",
            "  Min:  0.0000\n",
            "  Max:  4.0662\n",
            "  Zeros: 156 / 1000\n",
            "\n",
            "Arm 1:\n",
            "  Mean: 0.5722\n",
            "  Std:  0.6336\n",
            "  Min:  0.0000\n",
            "  Max:  4.4076\n",
            "  Zeros: 277 / 1000\n",
            "\n",
            "Arm 2:\n",
            "  Mean: 0.9267\n",
            "  Std:  0.8479\n",
            "  Min:  0.0000\n",
            "  Max:  4.8858\n",
            "  Zeros: 111 / 1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Collect many samples from each arm\n",
        "n_samples = 1000\n",
        "rewards = {0: [], 1: [], 2: []}\n",
        "\n",
        "for arm in range(3):\n",
        "    for _ in range(n_samples):\n",
        "        rewards[arm].append(bandit0.get_reward(arm))\n",
        "\n",
        "# Display basic statistics\n",
        "for arm in range(3):\n",
        "    arm_rewards = rewards[arm]\n",
        "    print(f\"Arm {arm}:\")\n",
        "    print(f\"  Mean: {np.mean(arm_rewards):.4f}\")\n",
        "    print(f\"  Std:  {np.std(arm_rewards):.4f}\")\n",
        "    print(f\"  Min:  {np.min(arm_rewards):.4f}\")\n",
        "    print(f\"  Max:  {np.max(arm_rewards):.4f}\")\n",
        "    print(f\"  Zeros: {np.sum(np.array(arm_rewards) == 0)} / {n_samples}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x400 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arm 0 rewards in [0,1]: False\n",
            "Arm 1 rewards in [0,1]: False\n",
            "Arm 2 rewards in [0,1]: False\n"
          ]
        }
      ],
      "source": [
        "# Create histograms for each arm\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "for arm in range(3):\n",
        "    axes[arm].hist(rewards[arm], bins=50, alpha=0.7, density=True)\n",
        "    axes[arm].set_title(f'Arm {arm} Reward Distribution')\n",
        "    axes[arm].set_xlabel('Reward')\n",
        "    axes[arm].set_ylabel('Density')\n",
        "    axes[arm].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check if rewards are bounded between 0 and 1\n",
        "for arm in range(3):\n",
        "    arm_rewards = np.array(rewards[arm])\n",
        "    in_bounds = np.all((arm_rewards >= 0) & (arm_rewards <= 1))\n",
        "    print(f\"Arm {arm} rewards in [0,1]: {in_bounds}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arm 0 statistics:\n",
            "  Mean: 0.8150\n",
            "  95th percentile: 2.4307\n",
            "  99th percentile: 2.9762\n",
            "  Fraction > 1: 0.304\n",
            "  Fraction = 0: 0.156\n",
            "\n",
            "Arm 1 statistics:\n",
            "  Mean: 0.5722\n",
            "  95th percentile: 1.8024\n",
            "  99th percentile: 2.7104\n",
            "  Fraction > 1: 0.174\n",
            "  Fraction = 0: 0.277\n",
            "\n",
            "Arm 2 statistics:\n",
            "  Mean: 0.9267\n",
            "  95th percentile: 2.6716\n",
            "  99th percentile: 3.5836\n",
            "  Fraction > 1: 0.354\n",
            "  Fraction = 0: 0.111\n",
            "\n",
            "Ranking by mean reward:\n",
            "1. Arm 2: 0.9267\n",
            "2. Arm 0: 0.8150\n",
            "3. Arm 1: 0.5722\n"
          ]
        }
      ],
      "source": [
        "# Check for potential scaling issues\n",
        "for arm in range(3):\n",
        "    arm_rewards = np.array(rewards[arm])\n",
        "    print(f\"Arm {arm} statistics:\")\n",
        "    print(f\"  Mean: {np.mean(arm_rewards):.4f}\")\n",
        "    print(f\"  95th percentile: {np.percentile(arm_rewards, 95):.4f}\")\n",
        "    print(f\"  99th percentile: {np.percentile(arm_rewards, 99):.4f}\")\n",
        "    print(f\"  Fraction > 1: {np.mean(arm_rewards > 1):.3f}\")\n",
        "    print(f\"  Fraction = 0: {np.mean(arm_rewards == 0):.3f}\")\n",
        "    print()\n",
        "\n",
        "# Check if we can identify the best arm\n",
        "print(\"Ranking by mean reward:\")\n",
        "arm_means = [np.mean(rewards[arm]) for arm in range(3)]\n",
        "ranked_arms = sorted(range(3), key=lambda x: arm_means[x], reverse=True)\n",
        "for i, arm in enumerate(ranked_arms):\n",
        "    print(f\"{i+1}. Arm {arm}: {arm_means[arm]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum rewards observed: [np.float64(4.066220476820962), np.float64(4.407634897505849), np.float64(4.885846547724117)]\n",
            "Global maximum reward: 4.8858\n",
            "Rewards <= 2: 92.4%\n",
            "Rewards <= 3: 98.8%\n",
            "Rewards <= 4: 99.9%\n",
            "Rewards <= 5: 100.0%\n"
          ]
        }
      ],
      "source": [
        "# Since rewards are unbounded, UCB1 cannot be used directly\n",
        "# Let's see if we can bound or transform the rewards\n",
        "\n",
        "# Check if rewards have a reasonable upper bound for practical purposes\n",
        "max_rewards = [np.max(rewards[arm]) for arm in range(3)]\n",
        "print(\"Maximum rewards observed:\", max_rewards)\n",
        "\n",
        "# Check the distribution shape to see if Thompson sampling is viable\n",
        "# (Thompson sampling doesn't require bounded rewards)\n",
        "\n",
        "# Consider if we can normalize rewards\n",
        "all_rewards = np.concatenate([rewards[arm] for arm in range(3)])\n",
        "global_max = np.max(all_rewards)\n",
        "print(f\"Global maximum reward: {global_max:.4f}\")\n",
        "\n",
        "# Let's check what percentage of rewards would be preserved if we cap at certain values\n",
        "for cap in [2, 3, 4, 5]:\n",
        "    preserved = np.mean(all_rewards <= cap)\n",
        "    print(f\"Rewards <= {cap}: {preserved:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After 100 rounds:\n",
            "Arm counts: [27, 29, 44]\n",
            "Normalized averages: ['0.1709', '0.1861', '0.2921']\n"
          ]
        }
      ],
      "source": [
        "# Based on the analysis, I'll implement UCB1 with reward normalization\n",
        "# Since 99.9% of rewards are <= 4, I'll cap and normalize by dividing by 4\n",
        "\n",
        "import math\n",
        "\n",
        "class UCB1_Normalized:\n",
        "    def __init__(self, n_arms, reward_cap=4.0):\n",
        "        self.n_arms = n_arms\n",
        "        self.reward_cap = reward_cap\n",
        "        self.counts = [0] * n_arms\n",
        "        self.totals = [0.0] * n_arms\n",
        "        self.t = 0\n",
        "        \n",
        "    def select_arm(self):\n",
        "        # If any arm hasn't been tried, try it\n",
        "        for arm in range(self.n_arms):\n",
        "            if self.counts[arm] == 0:\n",
        "                return arm\n",
        "        \n",
        "        # Calculate UCB1 values for each arm\n",
        "        ucb_values = []\n",
        "        for arm in range(self.n_arms):\n",
        "            avg_reward = self.totals[arm] / self.counts[arm]\n",
        "            confidence = math.sqrt(2 * math.log(self.t) / self.counts[arm])\n",
        "            ucb_values.append(avg_reward + confidence)\n",
        "        \n",
        "        return ucb_values.index(max(ucb_values))\n",
        "    \n",
        "    def update(self, arm, reward):\n",
        "        # Normalize reward by capping and scaling\n",
        "        normalized_reward = min(reward, self.reward_cap) / self.reward_cap\n",
        "        \n",
        "        self.counts[arm] += 1\n",
        "        self.totals[arm] += normalized_reward\n",
        "        self.t += 1\n",
        "    \n",
        "    def get_averages(self):\n",
        "        return [self.totals[arm] / max(self.counts[arm], 1) for arm in range(self.n_arms)]\n",
        "\n",
        "# Test the algorithm\n",
        "algorithm = UCB1_Normalized(n_arms=3)\n",
        "bandit_test = BanditProblem(0)\n",
        "\n",
        "# Run for 100 rounds to test\n",
        "for round_num in range(100):\n",
        "    arm = algorithm.select_arm()\n",
        "    reward = bandit_test.get_reward(arm)\n",
        "    algorithm.update(arm, reward)\n",
        "\n",
        "print(\"After 100 rounds:\")\n",
        "print(f\"Arm counts: {algorithm.counts}\")\n",
        "print(f\"Normalized averages: {[f'{avg:.4f}' for avg in algorithm.get_averages()]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Thompson sampling is rejected because the reward distribution (mixture of zeros and continuous positive values) doesn't fit the Bernoulli assumption required for beta distributions covered in the course. \n",
        "The epsilon-greedy algorithm lacks the theoretical guarantees and automatic exploration-exploitation balance that UCB1 provides.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Algorithm choice written to algorithm-choice.txt\n",
            "\n",
            "Content:\n",
            "I chose the algorithm: UCB1 with reward normalization.\n",
            "The rewards violate UCB1's [0,1] requirement, with maximum observed rewards near 5.0. \n",
            "However, as discussed in the course materials, UCB1 can be applied by normalizing rewards (dividing by a constant c when rewards are in [0,c]). \n",
            "Since 99.9% of rewards fall below 4.0, capping and normalizing by 4.0 preserves nearly all reward information while enabling UCB1's proven regret bounds.\n",
            "UCB1's upper confidence bound mechanism will efficiently identify Arm 2 as optimal (mean 0.93 vs 0.82 and 0.57 for other arms) while maintaining sufficient exploration as demonstrated in course examples.\n"
          ]
        }
      ],
      "source": [
        "# Write the algorithm choice justification using code instead of manual creation\n",
        "algorithm_choice_text = \"\"\"I chose the algorithm: UCB1 with reward normalization.\n",
        "The rewards violate UCB1's [0,1] requirement, with maximum observed rewards near 5.0. \n",
        "However, as discussed in the course materials, UCB1 can be applied by normalizing rewards (dividing by a constant c when rewards are in [0,c]). \n",
        "Since 99.9% of rewards fall below 4.0, capping and normalizing by 4.0 preserves nearly all reward information while enabling UCB1's proven regret bounds.\n",
        "UCB1's upper confidence bound mechanism will efficiently identify Arm 2 as optimal (mean 0.93 vs 0.82 and 0.57 for other arms) while maintaining sufficient exploration as demonstrated in course examples.\"\"\"\n",
        "\n",
        "with open('algorithm-choice.txt', 'w') as f:\n",
        "    f.write(algorithm_choice_text)\n",
        "\n",
        "print(\"Algorithm choice written to algorithm-choice.txt\")\n",
        "print(\"\\nContent:\")\n",
        "print(algorithm_choice_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4-3KtNXtzlY"
      },
      "source": [
        "Based on your investigation, pick an appropriate bandit algorithm to implement from the algorithms covered this week.\n",
        "Write a file \"algorithm-choice.txt\" that states your choice and gives a few sentences justifying your choice and rejecting the alternatives.\n",
        "Keep your explanation concise; overly verbose responses will be penalized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY_xvfK4rN0C"
      },
      "source": [
        "## Part 2: Implement Bandit\n",
        "\n",
        "Based on your decision, implement an appropriate bandit algorithm and pick 1000 actions using seed 2025002."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "kufc5pAPrWTT"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "class UCB1_Normalized:\n",
        "    def __init__(self, n_arms, reward_cap=4.0):\n",
        "        self.n_arms = n_arms\n",
        "        self.reward_cap = reward_cap\n",
        "        self.counts = [0] * n_arms\n",
        "        self.totals = [0.0] * n_arms\n",
        "        self.t = 0\n",
        "        \n",
        "    def select_arm(self):\n",
        "        # If any arm hasn't been tried, try it\n",
        "        for arm in range(self.n_arms):\n",
        "            if self.counts[arm] == 0:\n",
        "                return arm\n",
        "        \n",
        "        # Calculate UCB1 values for each arm\n",
        "        ucb_values = []\n",
        "        for arm in range(self.n_arms):\n",
        "            avg_reward = self.totals[arm] / self.counts[arm]\n",
        "            confidence = math.sqrt(2 * math.log(self.t) / self.counts[arm])\n",
        "            ucb_values.append(avg_reward + confidence)\n",
        "        \n",
        "        return ucb_values.index(max(ucb_values))\n",
        "    \n",
        "    def update(self, arm, reward):\n",
        "        # Normalize reward by capping and scaling\n",
        "        normalized_reward = min(reward, self.reward_cap) / self.reward_cap\n",
        "        \n",
        "        self.counts[arm] += 1\n",
        "        self.totals[arm] += normalized_reward\n",
        "        self.t += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed 1000 actions\n",
            "Final arm counts: [420, 399, 181]\n",
            "Total reward: 494.3640725234027\n",
            "Average reward per round: 0.4943640725234027\n"
          ]
        }
      ],
      "source": [
        "# Initialize bandit problem and algorithm\n",
        "bandit = BanditProblem(2025002)\n",
        "algorithm = UCB1_Normalized(n_arms=3)\n",
        "\n",
        "# Run for 1000 actions and record history\n",
        "history = []\n",
        "total_reward = 0\n",
        "\n",
        "for round_num in range(1000):\n",
        "    arm = algorithm.select_arm()\n",
        "    reward = bandit.get_reward(arm)\n",
        "    algorithm.update(arm, reward)\n",
        "    \n",
        "    history.append((arm, reward))\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"Completed 1000 actions\")\n",
        "print(f\"Final arm counts: {algorithm.counts}\")\n",
        "print(f\"Total reward: {total_reward}\")\n",
        "print(f\"Average reward per round: {total_reward/1000}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho9QihatrZqy"
      },
      "source": [
        "Write a file \"history.tsv\" with columns action and reward in the order that the actions were taken."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "OsiU7S1XrX0q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "History written to history.tsv\n",
            "\n",
            "First 10 rows:\n",
            "Action: 0, Reward: 1.5752073596631015\n",
            "Action: 1, Reward: 0.0\n",
            "Action: 2, Reward: 0.0\n",
            "Action: 0, Reward: 1.80400593080568\n",
            "Action: 1, Reward: 0.4320834323714654\n",
            "Action: 2, Reward: 0.0\n",
            "Action: 0, Reward: 0.0\n",
            "Action: 1, Reward: 0.41087663304602884\n",
            "Action: 0, Reward: 0.7799326730626841\n",
            "Action: 2, Reward: 0.0\n",
            "\n",
            "Summary:\n",
            "Total actions: 1000\n",
            "Arm 0 selected: 420 times\n",
            "Arm 1 selected: 399 times\n",
            "Arm 2 selected: 181 times\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Write history to TSV file\n",
        "with open('history.tsv', 'w') as f:\n",
        "    f.write(\"action\\treward\\n\")\n",
        "    for action, reward in history:\n",
        "        f.write(f\"{action}\\t{reward}\\n\")\n",
        "\n",
        "print(\"History written to history.tsv\")\n",
        "\n",
        "# Show first few rows and summary statistics\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "for i in range(10):\n",
        "    action, reward = history[i]\n",
        "    print(f\"Action: {action}, Reward: {reward}\")\n",
        "\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"Total actions: {len(history)}\")\n",
        "actions_taken = [action for action, reward in history]\n",
        "print(f\"Arm 0 selected: {actions_taken.count(0)} times\")\n",
        "print(f\"Arm 1 selected: {actions_taken.count(1)} times\") \n",
        "print(f\"Arm 2 selected: {actions_taken.count(2)} times\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwm-1x3mrfXu"
      },
      "source": [
        "Submit \"history.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc0xYgCzrmGj"
      },
      "source": [
        "## Part 3: Action Statistics\n",
        "\n",
        "Based on the data from part 2, estimate the expected reward for each arm and write a file \"actions.tsv\" with the columns action, min_reward, mean_reward, max_reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "a-uAbY03sFna"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action statistics from 1000 rounds:\n",
            "Arm 0: 420 selections\n",
            "  Min:  0.0000\n",
            "  Mean: 0.5710\n",
            "  Max:  2.9889\n",
            "\n",
            "Arm 1: 399 selections\n",
            "  Min:  0.0000\n",
            "  Mean: 0.5524\n",
            "  Max:  3.7615\n",
            "\n",
            "Arm 2: 181 selections\n",
            "  Min:  0.0000\n",
            "  Mean: 0.1884\n",
            "  Max:  0.9869\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Calculate statistics for each arm based on the data from part 2\n",
        "arm_stats = {}\n",
        "\n",
        "# Group rewards by action (arm)\n",
        "for arm in range(3):\n",
        "    arm_rewards = [reward for action, reward in history if action == arm]\n",
        "    \n",
        "    if len(arm_rewards) > 0:\n",
        "        arm_stats[arm] = {\n",
        "            'min_reward': min(arm_rewards),\n",
        "            'mean_reward': np.mean(arm_rewards),\n",
        "            'max_reward': max(arm_rewards),\n",
        "            'count': len(arm_rewards)\n",
        "        }\n",
        "    else:\n",
        "        # Handle case where arm was never selected (shouldn't happen with UCB1)\n",
        "        arm_stats[arm] = {\n",
        "            'min_reward': 0.0,\n",
        "            'mean_reward': 0.0,\n",
        "            'max_reward': 0.0,\n",
        "            'count': 0\n",
        "        }\n",
        "\n",
        "# Display the statistics\n",
        "print(\"Action statistics from 1000 rounds:\")\n",
        "for arm in range(3):\n",
        "    stats = arm_stats[arm]\n",
        "    print(f\"Arm {arm}: {stats['count']} selections\")\n",
        "    print(f\"  Min:  {stats['min_reward']:.4f}\")\n",
        "    print(f\"  Mean: {stats['mean_reward']:.4f}\")\n",
        "    print(f\"  Max:  {stats['max_reward']:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action statistics written to actions.tsv\n",
            "\n",
            "File contents:\n",
            "action\tmin_reward\tmean_reward\tmax_reward\n",
            "0\t0.000000\t0.571040\t2.988922\n",
            "1\t0.000000\t0.552435\t3.761461\n",
            "2\t0.000000\t0.188430\t0.986928\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Write action statistics to TSV file\n",
        "with open('actions.tsv', 'w') as f:\n",
        "    f.write(\"action\\tmin_reward\\tmean_reward\\tmax_reward\\n\")\n",
        "    for arm in range(3):\n",
        "        stats = arm_stats[arm]\n",
        "        f.write(f\"{arm}\\t{stats['min_reward']:.6f}\\t{stats['mean_reward']:.6f}\\t{stats['max_reward']:.6f}\\n\")\n",
        "\n",
        "print(\"Action statistics written to actions.tsv\")\n",
        "\n",
        "# Verify the file contents\n",
        "print(\"\\nFile contents:\")\n",
        "with open('actions.tsv', 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk8s1hpEsHWX"
      },
      "source": [
        "Submit \"actions.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asaIrLTtsKEv"
      },
      "source": [
        "## Part 4: Regret Estimates\n",
        "\n",
        "Calculate the expected regret taking 1000 actions with the following strategies.\n",
        "\n",
        "* uniform: Pick an arm uniformly at random.\n",
        "* just-i: Always pick arm $i$. Do this for $i=0$ to $K-1$ where $K$ is the number of arms.\n",
        "* actual: This should match your output in part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "LgCSJKDmso5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data from actions.tsv:\n",
            "   action  min_reward  mean_reward  max_reward\n",
            "0       0         0.0     0.571040    2.988922\n",
            "1       1         0.0     0.552435    3.761461\n",
            "2       2         0.0     0.188430    0.986928\n",
            "\n",
            "True means extracted from file: {0: np.float64(0.57104), 1: np.float64(0.552435), 2: np.float64(0.18843)}\n",
            "Optimal arm: 0 with expected reward: 0.57104\n",
            "\n",
            "Regret calculations:\n",
            "uniform: 133.73833333333334\n",
            "just-0: 0.0\n",
            "just-1: 18.604999999999983\n",
            "just-2: 382.61\n",
            "actual: 76.67592747659722\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import pandas as pd\n",
        "\n",
        "# Regret = (Best possible reward - Actual reward achieved)\n",
        "\n",
        "# Read the true means from the actions.tsv file we created\n",
        "actions_df = pd.read_csv('actions.tsv', sep='\\t')\n",
        "print(\"Data from actions.tsv:\")\n",
        "print(actions_df)\n",
        "\n",
        "# From our data, we know the true expected rewards for each arm\n",
        "# Create dictionary of true means from the file\n",
        "true_means = {}\n",
        "for _, row in actions_df.iterrows():\n",
        "    true_means[int(row['action'])] = row['mean_reward']\n",
        "\n",
        "print(f\"\\nTrue means extracted from file: {true_means}\")\n",
        "\n",
        "# Find the optimal arm (highest expected reward)\n",
        "optimal_arm = max(true_means.keys(), key=lambda x: true_means[x])\n",
        "optimal_reward = true_means[optimal_arm]\n",
        "print(f\"Optimal arm: {optimal_arm} with expected reward: {optimal_reward}\")\n",
        "\n",
        "# Calculate regret for each strategy over 1000 actions\n",
        "strategies = {}\n",
        "\n",
        "# 1. Pick an arm uniformly at random\n",
        "uniform_expected_reward = sum(true_means.values()) / len(true_means)\n",
        "uniform_regret = 1000 * (optimal_reward - uniform_expected_reward)\n",
        "strategies['uniform'] = uniform_regret\n",
        "\n",
        "# 2. Always pick arm i strategies\n",
        "for i in range(3):\n",
        "    just_i_regret = 1000 * (optimal_reward - true_means[i])\n",
        "    strategies[f'just-{i}'] = just_i_regret\n",
        "\n",
        "# 3. Actual strategy (our UCB1 results)\n",
        "actual_total_reward = sum(reward for _, reward in history)\n",
        "actual_regret = 1000 * optimal_reward - actual_total_reward\n",
        "strategies['actual'] = actual_regret\n",
        "\n",
        "print(\"\\nRegret calculations:\")\n",
        "for strategy, regret in strategies.items():\n",
        "    print(f\"{strategy}: {regret}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncXs2IqPsqQO"
      },
      "source": [
        "Write your results to a file \"strategies.tsv\" with the columns strategy and regret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "GlYK-oCUtyFm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regret analysis written to strategies.tsv\n",
            "\n",
            "File contents:\n",
            "strategy\tregret\n",
            "uniform\t133.73833333333334\n",
            "just-0\t0.0\n",
            "just-1\t18.604999999999983\n",
            "just-2\t382.61\n",
            "actual\t76.67592747659722\n",
            "\n",
            "Strategy performance ranking (lower regret is better):\n",
            "1. just-0: 0.0\n",
            "2. just-1: 18.604999999999983\n",
            "3. actual: 76.67592747659722\n",
            "4. uniform: 133.73833333333334\n",
            "5. just-2: 382.61\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "with open('strategies.tsv', 'w') as f:\n",
        "    f.write(\"strategy\\tregret\\n\")\n",
        "    for strategy, regret in strategies.items():\n",
        "        f.write(f\"{strategy}\\t{regret}\\n\")\n",
        "\n",
        "print(\"Regret analysis written to strategies.tsv\")\n",
        "\n",
        "# Verify the file contents\n",
        "print(\"\\nFile contents:\")\n",
        "with open('strategies.tsv', 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "# Additional analysis\n",
        "print(\"Strategy performance ranking (lower regret is better):\")\n",
        "sorted_strategies = sorted(strategies.items(), key=lambda x: x[1])\n",
        "for i, (strategy, regret) in enumerate(sorted_strategies):\n",
        "    print(f\"{i+1}. {strategy}: {regret}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNs9BJCvtz2N"
      },
      "source": [
        "Submit \"strategies.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lopxdy3lsysb"
      },
      "source": [
        "## Part 5: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acknowledgments written to acknowledgments.txt\n",
            "File size: 10873 characters\n",
            "\n",
            "First few lines:\n",
            "ACKNOWLEDGMENTS\n",
            "\n",
            "Course Materials and Resources:\n",
            "- Week 3 course materials on multi-armed bandit algorithms, including UCB1 algorithm explanation and implementation guidance\n",
            "- Course documentation on UCB1 reward normalization technique for unbounded rewards (dividing by constant c when rewards are in [0,c])\n",
            "- Course materials on Thompson sampling with beta distributions and Bernoulli reward assumptions\n",
            "- Course materials on epsilon-greedy algorithm and exploration-exploitation tradeoffs\n",
            "- Example code from materials showing UCB1 implementation patterns and bandit problem class structure\n",
            "- Course content on regret calculation methodology and performance evaluation metrics for bandit algorithms\n",
            "- Bandit Algorithms by Tor Lattimore and Csaba Szepesv´ari https://tor-lattimore.com/downloads/book/book.pdf\n"
          ]
        }
      ],
      "source": [
        "acknowledgments_text = \"\"\"ACKNOWLEDGMENTS\n",
        "\n",
        "Course Materials and Resources:\n",
        "- Week 3 course materials on multi-armed bandit algorithms, including UCB1 algorithm explanation and implementation guidance\n",
        "- Course documentation on UCB1 reward normalization technique for unbounded rewards (dividing by constant c when rewards are in [0,c])\n",
        "- Course materials on Thompson sampling with beta distributions and Bernoulli reward assumptions\n",
        "- Course materials on epsilon-greedy algorithm and exploration-exploitation tradeoffs\n",
        "- Example code from materials showing UCB1 implementation patterns and bandit problem class structure\n",
        "- Course content on regret calculation methodology and performance evaluation metrics for bandit algorithms\n",
        "- Bandit Algorithms by Tor Lattimore and Csaba Szepesv´ari https://tor-lattimore.com/downloads/book/book.pdf\n",
        "- Reinforcement Learning Guide: Solving the Multi-Armed Bandit Problem from Scratch in Python by Ankit Choudhary https://www.analyticsvidhya.com/blog/2018/09/reinforcement-multi-armed-bandit-scratch-python/\n",
        "- The Multi-Armed Bandit Problem - An exploration of epsilon greedy and UCB1 By: Michelle Yun, Deric Pang, Ayaz Latif https://cse442-17f.github.io/LinUCB/\n",
        "\n",
        "Libraries Used:\n",
        "- numpy: Random number generation, statistical calculations, and array operations for reward analysis\n",
        "- matplotlib.pyplot: Data visualization for reward distribution histograms and algorithm analysis\n",
        "- pandas: Reading and writing TSV files, data manipulation for actions.tsv processing\n",
        "- math: Mathematical functions for UCB1 confidence bound calculations (sqrt, log functions)\n",
        "\n",
        "Python Standard Library:\n",
        "- Built-in functions (min, max, sum) for statistical calculations\n",
        "- File I/O operations for writing TSV and TXT output files\n",
        "\n",
        "Generative AI Assistance:\n",
        "- AI helped with TSV file formatting:\n",
        "\n",
        "prompt: can you give me an exmaple of how to write to a tsv file in python\n",
        "response: Here's a simple example of writing to a TSV (Tab-Separated Values) file in Python:\n",
        "Using the csv module (recommended):\n",
        "pythonimport csv\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    ['Name', 'Age', 'City'],\n",
        "    ['Alice', '25', 'New York'],\n",
        "    ['Bob', '30', 'San Francisco'],\n",
        "    ['Charlie', '35', 'Chicago']\n",
        "]\n",
        "\n",
        "# Write to TSV file\n",
        "with open('output.tsv', 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file, delimiter='\\t')\n",
        "    writer.writerows(data)\n",
        "Alternative method using basic file operations:\n",
        "python# Sample data as list of dictionaries\n",
        "people = [\n",
        "    {'Name': 'Alice', 'Age': 25, 'City': 'New York'},\n",
        "    {'Name': 'Bob', 'Age': 30, 'City': 'San Francisco'},\n",
        "    {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}\n",
        "]\n",
        "\n",
        "with open('output.tsv', 'w', encoding='utf-8') as file:\n",
        "    # Write header\n",
        "    headers = list(people[0].keys())\n",
        "    file.write('\\t'.join(headers) + '\\n')\n",
        "    \n",
        "    # Write data rows\n",
        "    for person in people:\n",
        "        row = [str(person[key]) for key in headers]\n",
        "        file.write('\\t'.join(row) + '\\n')\n",
        "For pandas DataFrames:\n",
        "pythonimport pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [25, 30, 35],\n",
        "    'City': ['New York', 'San Francisco', 'Chicago']\n",
        "})\n",
        "\n",
        "# Write to TSV\n",
        "df.to_csv('output.tsv', sep='\\t', index=False)\n",
        "The csv module approach is generally preferred because it handles edge cases like data containing tabs or newlines properly by escaping them.\n",
        "\n",
        "prompt: can you give me an example of how to read a tsv file using pandas in python\n",
        "response: Here's how to read a TSV file using pandas in Python:\n",
        "Basic example:\n",
        "pythonimport pandas as pd\n",
        "\n",
        "# Read TSV file\n",
        "df = pd.read_csv('data.tsv', sep='\\t')\n",
        "\n",
        "# Display the data\n",
        "print(df)\n",
        "print(df.head())  # Show first 5 rows\n",
        "With common options:\n",
        "pythonimport pandas as pd\n",
        "\n",
        "# Read TSV with additional options\n",
        "df = pd.read_csv(\n",
        "    'data.tsv',\n",
        "    sep='\\t',                    # Tab separator\n",
        "    encoding='utf-8',            # Specify encoding\n",
        "    header=0,                    # First row contains column names\n",
        "    index_col=None,              # Don't use any column as index\n",
        "    na_values=['', 'NULL', 'N/A'] # Values to treat as NaN\n",
        ")\n",
        "\n",
        "print(df.info())  # Show data types and info\n",
        "print(df.head())\n",
        "Handling files without headers:\n",
        "pythonimport pandas as pd\n",
        "\n",
        "# If TSV file has no header row\n",
        "df = pd.read_csv(\n",
        "    'data.tsv',\n",
        "    sep='\\t',\n",
        "    header=None,  # No header row\n",
        "    names=['Name', 'Age', 'City']  # Specify column names\n",
        ")\n",
        "\n",
        "print(df)\n",
        "With data type specification:\n",
        "pythonimport pandas as pd\n",
        "\n",
        "# Specify data types for better performance and accuracy\n",
        "df = pd.read_csv(\n",
        "    'data.tsv',\n",
        "    sep='\\t',\n",
        "    dtype={\n",
        "        'Name': 'string',\n",
        "        'Age': 'int64',\n",
        "        'City': 'string'\n",
        "    }\n",
        ")\n",
        "\n",
        "print(df.dtypes)  # Check data types\n",
        "print(df)\n",
        "Handling large files (reading in chunks):\n",
        "pythonimport pandas as pd\n",
        "\n",
        "# For very large files, read in chunks\n",
        "chunk_size = 1000\n",
        "for chunk in pd.read_csv('large_data.tsv', sep='\\t', chunksize=chunk_size):\n",
        "    # Process each chunk\n",
        "    print(f\"Processing chunk with {len(chunk)} rows\")\n",
        "    # Your processing logic here\n",
        "The sep='\\t' parameter is the key difference from reading CSV files - it tells pandas to use tabs as the delimiter instead of commas.\n",
        "\n",
        "- AI was also used in understanding a generic example of how UCB1 is implemented in python\n",
        "prompt: can you give me a general example of how UCB1 is typically implemented for multi-armed bandit problems?\n",
        "response: \n",
        "Here's a typical implementation of the UCB1 algorithm for multi-armed bandit problems in Python:\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class UCB1Bandit:\n",
        "    def __init__(self, n_arms):\n",
        "        \\\"\\\"\\\"\n",
        "        Initialize UCB1 bandit algorithm\n",
        "        \n",
        "        Args:\n",
        "            n_arms: Number of arms (actions) available\n",
        "        \\\"\\\"\\\"\n",
        "        self.n_arms = n_arms\n",
        "        self.counts = np.zeros(n_arms)  # Number of times each arm was pulled\n",
        "        self.values = np.zeros(n_arms)  # Average reward for each arm\n",
        "        self.total_count = 0\n",
        "        \n",
        "    def select_arm(self):\n",
        "        \\\"\\\"\\\"\n",
        "        Select an arm using UCB1 algorithm\n",
        "        \n",
        "        Returns:\n",
        "            Selected arm index\n",
        "        \\\"\\\"\\\"\n",
        "        # If any arm hasn't been tried, select it first\n",
        "        for arm in range(self.n_arms):\n",
        "            if self.counts[arm] == 0:\n",
        "                return arm\n",
        "        \n",
        "        # Calculate UCB1 values for all arms\n",
        "        ucb_values = np.zeros(self.n_arms)\n",
        "        for arm in range(self.n_arms):\n",
        "            # UCB1 formula: average_reward + sqrt(2 * ln(total_pulls) / arm_pulls)\n",
        "            confidence_interval = np.sqrt(2 * np.log(self.total_count) / self.counts[arm])\n",
        "            ucb_values[arm] = self.values[arm] + confidence_interval\n",
        "        \n",
        "        # Select arm with highest UCB1 value\n",
        "        return np.argmax(ucb_values)\n",
        "    \n",
        "    def update(self, chosen_arm, reward):\n",
        "        \\\"\\\"\\\"\n",
        "        Update the bandit's knowledge after receiving a reward\n",
        "        \n",
        "        Args:\n",
        "            chosen_arm: Index of the arm that was pulled\n",
        "            reward: Reward received from pulling the arm\n",
        "        \\\"\\\"\\\"\n",
        "        self.counts[chosen_arm] += 1\n",
        "        self.total_count += 1\n",
        "        \n",
        "        # Update running average: new_avg = old_avg + (new_value - old_avg) / count\n",
        "        n = self.counts[chosen_arm]\n",
        "        self.values[chosen_arm] = ((n - 1) / n) * self.values[chosen_arm] + (1 / n) * reward\n",
        "    \n",
        "    def get_arm_info(self):\n",
        "        \\\"\\\"\\\"Return current arm statistics\\\"\\\"\\\"\n",
        "        return {\n",
        "            'counts': self.counts.copy(),\n",
        "            'values': self.values.copy(),\n",
        "            'total_count': self.total_count\n",
        "        }\n",
        "\n",
        "# Example usage with simulation\n",
        "def simulate_bandit_problem():\n",
        "    \\\"\\\"\\\"Simulate a multi-armed bandit problem\\\"\\\"\\\"\n",
        "    \n",
        "    # True reward probabilities for each arm (unknown to the algorithm)\n",
        "    true_rewards = [0.1, 0.3, 0.7, 0.2, 0.5]  # Arm 2 is best\n",
        "    n_arms = len(true_rewards)\n",
        "    n_rounds = 1000\n",
        "    \n",
        "    # Initialize UCB1 bandit\n",
        "    bandit = UCB1Bandit(n_arms)\n",
        "    \n",
        "    # Track results\n",
        "    chosen_arms = []\n",
        "    rewards_received = []\n",
        "    cumulative_rewards = []\n",
        "    cumulative_reward = 0\n",
        "    \n",
        "    # Run simulation\n",
        "    for round in range(n_rounds):\n",
        "        # Select arm using UCB1\n",
        "        chosen_arm = bandit.select_arm()\n",
        "        \n",
        "        # Simulate reward (Bernoulli trial with true probability)\n",
        "        reward = np.random.random() < true_rewards[chosen_arm]\n",
        "        \n",
        "        # Update bandit's knowledge\n",
        "        bandit.update(chosen_arm, reward)\n",
        "        \n",
        "        # Track results\n",
        "        chosen_arms.append(chosen_arm)\n",
        "        rewards_received.append(reward)\n",
        "        cumulative_reward += reward\n",
        "        cumulative_rewards.append(cumulative_reward)\n",
        "    \n",
        "    return {\n",
        "        'bandit': bandit,\n",
        "        'chosen_arms': chosen_arms,\n",
        "        'rewards': rewards_received,\n",
        "        'cumulative_rewards': cumulative_rewards,\n",
        "        'true_rewards': true_rewards\n",
        "    }\n",
        "\n",
        "# Run simulation\n",
        "if __name__ == \"__main__\":\n",
        "    results = simulate_bandit_problem()\n",
        "    bandit = results['bandit']\n",
        "    \n",
        "    print(\"UCB1 Multi-Armed Bandit Results\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Total rounds: {bandit.total_count}\")\n",
        "    print(f\"True reward rates: {results['true_rewards']}\")\n",
        "    print(f\"Estimated reward rates: {bandit.values}\")\n",
        "    print(f\"Arm selection counts: {bandit.counts}\")\n",
        "    print(f\"Total reward: {results['cumulative_rewards'][-1]}\")\n",
        "    \n",
        "    # Calculate regret (difference from optimal strategy)\n",
        "    optimal_reward = bandit.total_count * max(results['true_rewards'])\n",
        "    actual_reward = results['cumulative_rewards'][-1]\n",
        "    regret = optimal_reward - actual_reward\n",
        "    print(f\"Regret: {regret:.1f} (vs always picking best arm)\")\n",
        "    \n",
        "    # Show which arm was selected most often\n",
        "    best_arm_index = np.argmax(bandit.counts)\n",
        "    true_best_arm = np.argmax(results['true_rewards'])\n",
        "    print(f\"Most selected arm: {best_arm_index} (true best: {true_best_arm})\")\n",
        "\n",
        "This implementation demonstrates the key components of UCB1:\n",
        "Core Algorithm Components:\n",
        "\n",
        "Initialization: Track counts and average rewards for each arm\n",
        "Arm Selection: Use the UCB1 formula to balance exploration and exploitation\n",
        "Knowledge Update: Update statistics after each reward\n",
        "\n",
        "UCB1 Formula:\n",
        "The algorithm selects the arm with the highest UCB1 value:\n",
        "UCB1(i) = μᵢ + √(2 ln(t) / nᵢ)\n",
        "Where:\n",
        "\n",
        "μᵢ = average reward for arm i\n",
        "t = total number of pulls\n",
        "nᵢ = number of times arm i was pulled\n",
        "\n",
        "Key Features:\n",
        "Exploration vs Exploitation: The confidence interval (square root term) ensures exploration of less-tried arms, while the average reward term drives exploitation of promising arms.\n",
        "Theoretical Guarantees: UCB1 has proven logarithmic regret bounds, meaning it converges to optimal performance.\n",
        "Automatic Balancing: As arms are pulled more often, their confidence intervals shrink, naturally shifting from exploration to exploitation.\n",
        "The simulation shows how UCB1 gradually learns which arms are best and converges toward selecting the optimal arm most frequently. You can run this code to see how it performs across different scenarios!\n",
        "\n",
        "- All algorithm selection and implementation decisions were guided by course materials and requirements\n",
        "No collaboration with other students occurred on this assignment.\"\"\"\n",
        "\n",
        "# Write the acknowledgments to file\n",
        "with open('acknowledgments.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(acknowledgments_text)\n",
        "\n",
        "print(\"Acknowledgments written to acknowledgments.txt\")\n",
        "print(f\"File size: {len(acknowledgments_text)} characters\")\n",
        "print(\"\\nFirst few lines:\")\n",
        "print('\\n'.join(acknowledgments_text.split('\\n')[:10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8-GaDpOw06W"
      },
      "source": [
        "Submit \"acknowledgments.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AR_XyZi8N_Q"
      },
      "source": [
        "## Part 6: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXhGo_008M-b"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
